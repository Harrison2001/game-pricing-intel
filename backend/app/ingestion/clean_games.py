from pathlib import Path
import pandas as pd
from fastapi import HTTPException  # only used if you want to reuse load-style errors (optional)

# ============================================================
# clean_games.py
# Goal: Read ONE raw dataset (games.csv) and output ONE clean,
# analysis-ready dataset (games_clean.csv) that supports:
#   Q1) Seasonal pricing
#   Q2) Reviews vs price/features (genre/publisher)
#   Q3) Market pricing segments (free/paid/premium)
# ============================================================

# ------------------------------------------------------------
# Paths
# ------------------------------------------------------------
# Your file is: backend/app/ingestion/clean_games.py
# parents[3] -> project root (the folder that contains /data)
PROJECT_ROOT = Path(__file__).resolve().parents[3]

# Raw input CSV (do NOT edit this file manually)
RAW = PROJECT_ROOT / "data" / "games.csv"

# Clean output CSV (this is the "single source of truth")
OUT = PROJECT_ROOT / "data" / "games_clean.csv"


# ------------------------------------------------------------
# Helper: Convert month number -> season name
# This powers your seasonal pricing question.
# ------------------------------------------------------------
def month_to_season(month: int) -> str:
    if month in (12, 1, 2):
        return "Winter"
    if month in (3, 4, 5):
        return "Spring"
    if month in (6, 7, 8):
        return "Summer"
    return "Fall"


# ------------------------------------------------------------
# Helper: Quick debug print
# Use this when you want to see what the dataframe looks like.
# ------------------------------------------------------------
def debug_df(df: pd.DataFrame, label: str) -> None:
    print(f"\n--- {label} ---")
    print("shape:", df.shape)
    print("columns:", df.columns.tolist()[:50])
    print("head:")
    print(df.head(3).to_string(index=False))


# ------------------------------------------------------------
# Helper: Clean text columns consistently
# - converts to string
# - collapses multiple spaces
# - trims ends
# ------------------------------------------------------------
def _strip_text(s: pd.Series) -> pd.Series:
    return s.astype(str).str.replace(r"\s+", " ", regex=True).str.strip()


# ------------------------------------------------------------
# Helper: Convert a series to int safely
# - non-numeric -> NaN -> filled with 0
# - output as int64
# ------------------------------------------------------------
def _to_int(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce").fillna(0).astype("int64")


# ------------------------------------------------------------
# Helper: Convert a series to float safely
# - non-numeric -> NaN
# ------------------------------------------------------------
def _to_float(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")


# ------------------------------------------------------------
# Helper: Clean price column
# Handles:
#   "$19.99" -> 19.99
#   "Free" / "Free to Play" -> 0
#   "1,299.99" -> 1299.99
# ------------------------------------------------------------
def _clean_price_series(s: pd.Series) -> pd.Series:
    s = s.astype(str).str.strip()
    s = s.str.replace("$", "", regex=False)
    s = s.str.replace("Free to Play", "0", regex=False)
    s = s.str.replace("Free", "0", regex=False)
    s = s.str.replace(",", "", regex=False)
    return _to_float(s)


def main():
    # ------------------------------------------------------------
    # 1) Load raw CSV
    # ------------------------------------------------------------
    print(f"RAW path = {RAW.resolve()}")

    # Robust load:
    # - engine="python" handles weird quoting better sometimes
    # - on_bad_lines="skip" avoids crashing on broken rows
    df = pd.read_csv(
        RAW,
        sep=",",
        quotechar='"',
        engine="python",
        on_bad_lines="skip",
        keep_default_na=False  # empty strings stay empty instead of NaN
    )

    # Remove leading/trailing spaces in header names
    df.columns = df.columns.astype(str).str.strip()
    debug_df(df, "RAW LOADED")

    # ------------------------------------------------------------
    # 2) Optional "semantic shift" fix
    # Sometimes a dataset gets shifted so columns appear in the
    # wrong place (you observed this earlier).
    #
    # If:
    #   - df["Name"] looks like dates, and
    #   - df["AppID"] looks like real game names
    # then we swap them into correct meaning.
    # ------------------------------------------------------------
    def looks_like_dates(series: pd.Series) -> bool:
        parsed = pd.to_datetime(series.astype(str), errors="coerce", format="mixed")
        return parsed.notna().mean() > 0.6  # 60% parseable = likely dates

    def looks_like_names(series: pd.Series) -> bool:
        s = series.astype(str)
        return s.str.contains(r"[A-Za-z]", regex=True).mean() > 0.6  # likely text names

    if {"AppID", "Name", "Release date"}.issubset(df.columns):
        if looks_like_dates(df["Name"]) and looks_like_names(df["AppID"]):
            print("⚠️ Detected swapped columns: applying semantic-shift fix")

            # Save original meanings
            original_release_date = df["Name"]
            original_est_owners = df["Release date"]

            # Remap into correct meanings
            df["Name"] = df["AppID"]                 # now Name is the real game name
            df["Release date"] = original_release_date
            df["Estimated owners"] = original_est_owners

    # ------------------------------------------------------------
    # 3) Standardize column names
    # We rename any "variants" into ONE consistent schema.
    #
    # Why: Your API + charts should never break due to
    # different capitalization/spaces in raw data.
    # ------------------------------------------------------------
    rename_map = {
        # Release date
        "Release date": "ReleaseDate",
        "release_date": "ReleaseDate",
        "ReleaseDate": "ReleaseDate",

        # Owners bucket
        "Estimated owners": "EstimatedOwners",
        "Estimated Owners": "EstimatedOwners",
        "owners": "EstimatedOwners",
        "Owners": "EstimatedOwners",

        # Price
        "Price": "Price",
        "price": "Price",

        # Genres
        "Genres": "Genres",
        "genres": "Genres",

        # Publisher
        "Publisher": "Publisher",
        "publisher": "Publisher",

        # Reviews
        "Positive": "PositiveReviews",
        "positive": "PositiveReviews",
        "Positive reviews": "PositiveReviews",

        "Negative": "NegativeReviews",
        "negative": "NegativeReviews",
        "Negative reviews": "NegativeReviews",
    }
    df = df.rename(columns={c: rename_map[c] for c in df.columns if c in rename_map})

    # ------------------------------------------------------------
    # 4) Keep only columns relevant to your 3 business questions
    # If some are missing in raw data, we will create them with defaults.
    # ------------------------------------------------------------
    target_cols = [
        "Name",
        "ReleaseDate",
        "Price",
        "EstimatedOwners",
        "Genres",
        "Publisher",
        "PositiveReviews",
        "NegativeReviews",
    ]

    # Keep columns that exist
    keep = [c for c in target_cols if c in df.columns]
    missing = [c for c in target_cols if c not in df.columns]

    print("Keeping columns:", keep)
    if missing:
        print("Missing (will be filled with defaults):", missing)

    df = df[keep].copy()

    # Ensure ALL target columns exist (fill missing with blanks)
    for c in target_cols:
        if c not in df.columns:
            df[c] = ""

    # ------------------------------------------------------------
    # 5) Clean text fields
    # - trim whitespace
    # - replace empty values for categories with "Unknown"
    # ------------------------------------------------------------
    df["Name"] = _strip_text(df["Name"])
    df["Genres"] = _strip_text(df["Genres"])
    df["Publisher"] = _strip_text(df["Publisher"])
    df["EstimatedOwners"] = _strip_text(df["EstimatedOwners"])

    # For categorical fields, blank -> Unknown (so groupby works)
    df["Genres"] = df["Genres"].replace({"": "Unknown"})
    df["Publisher"] = df["Publisher"].replace({"": "Unknown"})
    df["EstimatedOwners"] = df["EstimatedOwners"].replace({"": "Unknown"})

    # ------------------------------------------------------------
    # 6) Clean price and derive IsFree
    # This supports:
    #   - free vs paid split
    #   - pricing segments
    # ------------------------------------------------------------
    df["Price"] = _clean_price_series(df["Price"])
    df["IsFree"] = df["Price"].fillna(0).eq(0)

    # ------------------------------------------------------------
    # 7) Parse ReleaseDate and derive time fields
    # This supports:
    #   - average price by month
    #   - median price by season
    #   - releases count by month
    # ------------------------------------------------------------
    df["ReleaseDate"] = _strip_text(df["ReleaseDate"])
    dt = pd.to_datetime(df["ReleaseDate"], errors="coerce", format="mixed")

    df["ReleaseYear"] = dt.dt.year
    df["ReleaseMonth"] = dt.dt.month
    df["ReleaseSeason"] = df["ReleaseMonth"].apply(
        lambda m: month_to_season(int(m)) if pd.notna(m) else pd.NA
    )

    # ------------------------------------------------------------
# 8) Clean review columns and derive review metrics
# ------------------------------------------------------------
    df["PositiveReviews"] = _to_int(df["PositiveReviews"])
    df["NegativeReviews"] = _to_int(df["NegativeReviews"])

    df["TotalReviews"] = df["PositiveReviews"] + df["NegativeReviews"]

# Use nullable float so <NA> is allowed
    denom = df["TotalReviews"].replace({0: pd.NA}).astype("Float64")
    num = df["PositiveReviews"].astype("Float64")

    df["ReviewRatio"] = (num / denom).astype("Float64")

    # ------------------------------------------------------------
    # 9) Final cleanup: remove empty names, drop duplicates
    # (You can switch to AppID if you have it later—better key.)
    # ------------------------------------------------------------
    df = df[df["Name"] != ""]
    df = df.drop_duplicates(subset=["Name"], keep="first")

    debug_df(df, "CLEANED FINAL")

    # ------------------------------------------------------------
    # 10) Save cleaned dataset (single source of truth)
    # ------------------------------------------------------------
    OUT.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(OUT, index=False)

    print(f"\n✅ Wrote cleaned file: {OUT.resolve()} rows={len(df):,}")
    print("Columns:", df.columns.tolist())
    print(df.head(10).to_string(index=False))


if __name__ == "__main__":
    main()
